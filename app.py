from __future__ import annotations

import os
import json
import orjson
import streamlit as st

from prompts import (
	ANALYZER_SYSTEM_PROMPT,
	ANALYZER_USER_TEMPLATE,
	EDITOR_SYSTEM_PROMPT,
	EDITOR_USER_TEMPLATE,
)
from llm_client import chat_json, chat_text
from pdf_utils import extract_text_from_pdf
from salary_estimator import estimate_salary_from_resume

ANALYZER_MODEL = os.getenv("ANALYZER_MODEL", "gpt-4o-mini")
EDITOR_MODEL = os.getenv("EDITOR_MODEL", "gpt-4o")

st.set_page_config(page_title="–ù–µ–π—Ä–æ‚ÄëHR ‚Äî –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–¥–∞–∫—Ç—É—Ä–∞ —Ä–µ–∑—é–º–µ", layout="wide")

st.title("üéØ –ù–µ–π—Ä–æ‚ÄëHR ‚Äî –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–¥–∞–∫—Ç—É—Ä–∞ —Ä–µ–∑—é–º–µ")

with st.sidebar:
	st.header("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
	resume_pdf = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF —Ä–µ–∑—é–º–µ", type=["pdf"])  # type: ignore
	job_description = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏", height=180)


def load_resume_text() -> str:
	if resume_pdf is not None:
		# Save to temp and extract
		tmp_path = os.path.join(st.session_state.get("tmp_dir", "."), "_resume_tmp.pdf")
		with open(tmp_path, "wb") as f:
			f.write(resume_pdf.getbuffer())
		return extract_text_from_pdf(tmp_path)
	return ""


def format_analysis_report(analysis_json: dict) -> str:
	"""–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç JSON-–æ—Ç—á—ë—Ç –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π Markdown"""
	report = []
	
	# –°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–æ–ª–µ–π, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –≤—ã–≤–µ—Å—Ç–∏ –æ—Å—Ç–∞–ª—å–Ω—ã–µ
	processed_fields = set()
	
	# –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
	if "overall_assessment" in analysis_json:
		report.append(f"### –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞\n{analysis_json['overall_assessment']}\n")
		processed_fields.add("overall_assessment")
	
	# –¢–æ–ø –ø—Ä–æ–±–ª–µ–º
	if "top_issues" in analysis_json and analysis_json["top_issues"]:
		report.append("### –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã")
		for i, issue in enumerate(analysis_json["top_issues"], 1):
			severity = issue.get("severity", "medium")
			severity_badge = {
				"high": "**–ö–†–ò–¢–ò–ß–ù–û**", 
				"medium": "**–í–ê–ñ–ù–û**", 
				"low": "**–ú–ï–õ–ö–û**"
			}.get(severity, "**–í–ê–ñ–ù–û**")
			
			report.append(f"#### {i}. {severity_badge}")
			report.append(f"**–ü—Ä–æ–±–ª–µ–º–∞:** {issue.get('issue', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞')}")
			report.append(f"**–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:** {issue.get('why', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
			report.append(f"**–†–µ—à–µ–Ω–∏–µ:** {issue.get('fix_suggestion', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}\n")
		processed_fields.add("top_issues")
	
	# –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
	if "missing_data" in analysis_json and analysis_json["missing_data"]:
		report.append("## –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ")
		for missing in analysis_json["missing_data"]:
			field_name = missing.get('field', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –ø–æ–ª–µ')
			field_display = {
				"metric": "–ú–µ—Ç—Ä–∏–∫–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
				"dates": "–î–∞—Ç—ã —Ä–∞–±–æ—Ç—ã", 
				"location": "–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ",
				"education": "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ",
				"contact": "–ö–æ–Ω—Ç–∞–∫—Ç—ã",
				"skills": "–ù–∞–≤—ã–∫–∏"
			}.get(field_name, f"{field_name}")
			report.append(f"- **{field_display}:** {missing.get('note', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
		report.append("")
		processed_fields.add("missing_data")
	
	# –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
	if "keywords_match" in analysis_json:
		keywords = analysis_json["keywords_match"]
		report.append("### –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
		if keywords.get("found_in_resume"):
			report.append(f"**–ù–∞–π–¥–µ–Ω–æ –≤ —Ä–µ–∑—é–º–µ:** {', '.join(keywords['found_in_resume'])}")
		if keywords.get("missing"):
			report.append(f"**–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç:** {', '.join(keywords['missing'])}")
		report.append("")
		processed_fields.add("keywords_match")
	
	# –†–∏—Å–∫–∏
	if "risks" in analysis_json and analysis_json["risks"]:
		report.append("### –†–∏—Å–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
		for risk in analysis_json["risks"]:
			report.append(f"- {risk}")
		report.append("")
		processed_fields.add("risks")
	
	# –í–æ–ø—Ä–æ—Å—ã –∫–∞–Ω–¥–∏–¥–∞—Ç—É
	if "candidate_questions" in analysis_json and analysis_json["candidate_questions"]:
		report.append("### –í–æ–ø—Ä–æ—Å—ã –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è")
		for i, question in enumerate(analysis_json["candidate_questions"], 1):
			report.append(f"{i}. {question}")
		report.append("")
		processed_fields.add("candidate_questions")
	
	# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
	if "priority_fix_list" in analysis_json and analysis_json["priority_fix_list"]:
		report.append("### –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π")
		for i, fix in enumerate(analysis_json["priority_fix_list"], 1):
			report.append(f"**{i}.** {fix}")
		report.append("")
		processed_fields.add("priority_fix_list")
	
	# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π (–¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ –∏ –º–µ—Ç—Ä–∏–∫)
	for key, value in analysis_json.items():
		if key in processed_fields:
			continue
		
		# –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (None, –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏/—Å–ª–æ–≤–∞—Ä–∏)
		if value is None:
			continue
		if isinstance(value, str) and not value.strip():
			continue
		if isinstance(value, (list, dict)) and len(value) == 0:
			continue
		
		# –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è (–∑–∞–≥–ª–∞–≤–Ω–∞—è –±—É–∫–≤–∞, –∑–∞–º–µ–Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π)
		# –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ø–æ–ª–µ–π "–æ—Ü–µ–Ω–∫–∞_*"
		if key.startswith("–æ—Ü–µ–Ω–∫–∞_") or "–æ—Ü–µ–Ω–∫–∞" in key.lower():
			field_title = key.replace("_", " ").title()
		else:
			field_title = key.replace("_", " ").title()
		
		# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π
		if isinstance(value, str):
			report.append(f"### {field_title}\n{value}\n")
		elif isinstance(value, dict):
			report.append(f"### {field_title}")
			for sub_key, sub_value in value.items():
				sub_title = str(sub_key).replace("_", " ").title()
				# –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º
				if sub_key == "—Ä–µ–π—Ç–∏–Ω–≥":
					sub_title = "–†–µ–π—Ç–∏–Ω–≥"
				elif sub_key == "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ":
					sub_title = "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"
				elif sub_key == "—Å—Ç–∞—Ç—É—Å":
					sub_title = "–°—Ç–∞—Ç—É—Å"
				elif sub_key == "justification":
					sub_title = "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"
				elif sub_key == "reason":
					sub_title = "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"
				elif sub_key == "rating":
					sub_title = "–†–µ–π—Ç–∏–Ω–≥"
				
				if isinstance(sub_value, str):
					report.append(f"**{sub_title}:** {sub_value}")
				elif isinstance(sub_value, (list, dict)) and len(sub_value) > 0:
					report.append(f"**{sub_title}:** {sub_value}")
				else:
					report.append(f"**{sub_title}:** {sub_value}")
			report.append("")
		elif isinstance(value, list):
			report.append(f"### {field_title}")
			for item in value:
				if isinstance(item, str):
					report.append(f"- {item}")
				elif isinstance(item, dict):
					# –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ä–µ–∫—Ç, –≤—ã–≤–æ–¥–∏–º –µ–≥–æ –ø–æ–ª—è
					for item_key, item_value in item.items():
						item_title = str(item_key).replace("_", " ").title()
						report.append(f"  - **{item_title}:** {item_value}")
				else:
					report.append(f"- {item}")
			report.append("")
		else:
			report.append(f"### {field_title}\n{value}\n")
	
	return "\n".join(report)


def format_salary_report(salary_json: dict) -> str:
	"""–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç JSON-–æ—Ç—á—ë—Ç –æ—Ü–µ–Ω–∫–∏ –∑–∞—Ä–ø–ª–∞—Ç—ã –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π Markdown"""
	report = []
	
	# –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã
	if "estimate_rub_month" in salary_json:
		est = salary_json["estimate_rub_month"]
		report.append("### üí∞ –û—Ü–µ–Ω–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã")
		min_val = est.get('min', 0)
		max_val = est.get('max', 0)
		if min_val and max_val:
			report.append(f"**–î–∏–∞–ø–∞–∑–æ–Ω:** {min_val:,} ‚Äî {max_val:,} —Ä—É–±/–º–µ—Å")
		else:
			report.append(f"**–î–∏–∞–ø–∞–∑–æ–Ω:** –Ω–µ —É–∫–∞–∑–∞–Ω–æ")
		if "median" in est and est.get('median'):
			report.append(f"**–ú–µ–¥–∏–∞–Ω–∞:** {est['median']:,} —Ä—É–±/–º–µ—Å")
		report.append("")
	
	# –†–æ–ª–∏
	if "roles" in salary_json and salary_json["roles"]:
		report.append("### –ü–æ–¥—Ö–æ–¥—è—â–∏–µ —Ä–æ–ª–∏")
		for i, role in enumerate(salary_json["roles"], 1):
			report.append(f"#### {i}. {role.get('title', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
			if role.get('direction'):
				report.append(f"**–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:** {role['direction']}")
			if role.get('seniority'):
				report.append(f"**–£—Ä–æ–≤–µ–Ω—å:** {role['seniority']}")
			if role.get('fit_reason'):
				report.append(f"**–ü–æ—á–µ–º—É –ø–æ–¥—Ö–æ–¥–∏—Ç:** {role['fit_reason']}")
			report.append("")
	
	# –î–∏–∞–ø–∞–∑–æ–Ω—ã –ø–æ —Ä–æ–ª—è–º
	if "ranges_per_role" in salary_json and salary_json["ranges_per_role"]:
		report.append("### –î–∏–∞–ø–∞–∑–æ–Ω—ã –∑–∞—Ä–ø–ª–∞—Ç –ø–æ —Ä–æ–ª—è–º")
		for role_range in salary_json["ranges_per_role"]:
			title = role_range.get('title', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')
			min_sal = role_range.get('min', 0)
			max_sal = role_range.get('max', 0)
			median_sal = role_range.get('median', 0)
			report.append(f"**{title}:** {min_sal:,} ‚Äî {max_sal:,} —Ä—É–±/–º–µ—Å (–º–µ–¥–∏–∞–Ω–∞: {median_sal:,})")
		report.append("")
	
	# –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
	if "confidence" in salary_json:
		confidence = salary_json["confidence"]
		confidence_ru = {
			"high": "–≤—ã—Å–æ–∫–∞—è",
			"medium": "—Å—Ä–µ–¥–Ω—è—è",
			"low": "–Ω–∏–∑–∫–∞—è"
		}.get(confidence, confidence)
		report.append(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏:** {confidence_ru}")
		report.append("")
	
	# –î–æ–ø—É—â–µ–Ω–∏—è
	if "assumptions" in salary_json and salary_json["assumptions"]:
		report.append("### –î–æ–ø—É—â–µ–Ω–∏—è")
		for assumption in salary_json["assumptions"]:
			report.append(f"- {assumption}")
		report.append("")
	
	# –ò—Å—Ç–æ—á–Ω–∏–∫–∏
	if "sources" in salary_json and salary_json["sources"]:
		report.append("### –ò—Å—Ç–æ—á–Ω–∏–∫–∏")
		for source in salary_json["sources"]:
			report.append(f"- {source}")
		report.append("")
	
	# –ü—Ä–∏–º–µ—á–∞–Ω–∏—è
	if "notes" in salary_json and salary_json["notes"]:
		report.append("### –ü—Ä–∏–º–µ—á–∞–Ω–∏—è")
		report.append(salary_json["notes"])
		report.append("")
	
	return "\n".join(report)


st.header("üîπ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä")
if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑"):
	resume_text = load_resume_text()
	if not resume_text:
		st.warning("–¢—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å PDF —Ä–µ–∑—é–º–µ")
	else:
		user_prompt = ANALYZER_USER_TEMPLATE.format(
			resume_text=resume_text,
			job_description=job_description or "",
		)
		messages = [
			{"role": "system", "content": ANALYZER_SYSTEM_PROMPT},
			{"role": "user", "content": user_prompt},
		]
		with st.spinner("–ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—é–º–µ‚Ä¶"):
			try:
				analysis_json = chat_json(
					messages=messages,
					model=ANALYZER_MODEL,
					temperature=0.1,
				)
				st.session_state["analysis_json"] = analysis_json
				st.success("–ì–æ—Ç–æ–≤–æ: –æ—Ç—á—ë—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω")
			except Exception as e:
				st.error(f"–û—à–∏–±–∫–∞ LLM: {e}")

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
if "analysis_json" in st.session_state:
	analysis_json = st.session_state["analysis_json"]
	st.markdown(format_analysis_report(analysis_json))


st.header("üîπ –†–µ–¥–∞–∫—Ç–æ—Ä")
if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–µ–∑—é–º–µ"):
	resume_text = load_resume_text()
	if not resume_text:
		st.warning("–¢—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å PDF —Ä–µ–∑—é–º–µ")
	else:
		if "analysis_json" not in st.session_state:
			st.info("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä ‚Äî –µ–≥–æ –≤—ã–≤–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –†–µ–¥–∞–∫—Ç–æ—Ä–æ–º")
		analysis_json_str = orjson.dumps(st.session_state.get("analysis_json", {})).decode()
		user_prompt = EDITOR_USER_TEMPLATE.format(
			analyzer_json=analysis_json_str,
			resume_text=resume_text,
			job_description=job_description or "",
		)
		messages = [
			{"role": "system", "content": EDITOR_SYSTEM_PROMPT},
			{"role": "user", "content": user_prompt},
		]
		with st.spinner("–ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—é–º–µ‚Ä¶"):
			try:
				editor_output = chat_text(
					messages=messages,
					model=EDITOR_MODEL,
					temperature=0.3,
				)
				st.session_state["editor_output"] = editor_output
				st.success("–ì–æ—Ç–æ–≤–æ: —Ä–µ–∑—é–º–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ")
			except Exception as e:
				st.error(f"–û—à–∏–±–∫–∞ LLM: {e}")

if "editor_output" in st.session_state:
	st.subheader("–ò—Ç–æ–≥ (Markdown —Å —Ä–∞–∑–¥–µ–ª–∞–º–∏)")
	st.markdown(st.session_state["editor_output"])  # Editor –≤—ã–≤–æ–¥–∏—Ç –ú–∞—Ä–∫–¥–∞—É–Ω –∏ —Å–ø–∏—Å–∫–∏


st.header("üîπ –û—Ü–µ–Ω–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã")
if st.button("–û—Ü–µ–Ω–∏—Ç—å –∑–∞—Ä–ø–ª–∞—Ç—É"):
	resume_text = load_resume_text()
	if not resume_text:
		st.warning("–¢—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å PDF —Ä–µ–∑—é–º–µ")
	else:
		with st.spinner("–ú–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∑–∞—Ä–ø–ª–∞—Ç—É‚Ä¶"):
			try:
				salary_json = estimate_salary_from_resume(
					resume_text=resume_text,
					job_description=job_description or None,
				)
				st.session_state["salary_json"] = salary_json
				st.success("–ì–æ—Ç–æ–≤–æ: –æ—Ü–µ–Ω–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∞")
			except Exception as e:
				st.error(f"–û—à–∏–±–∫–∞ LLM: {e}")

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –∑–∞—Ä–ø–ª–∞—Ç—ã
if "salary_json" in st.session_state:
	salary_json = st.session_state["salary_json"]
	st.markdown(format_salary_report(salary_json))

st.divider()

